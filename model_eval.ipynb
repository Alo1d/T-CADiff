{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision.transforms.v2 as v2\n",
    "from monai.metrics import HausdorffDistanceMetric, get_confusion_matrix, compute_confusion_matrix_metric, compute_iou\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from improved_diffusion.ss_unet import UNetModel_WithSSF\n",
    "from improved_diffusion.script_util import create_gaussian_diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_pad(img, image_size=224):\n",
    "    '''\n",
    "    对图像进行Square Pad，输入图像size为3*H*W\n",
    "    返回图像size为1*3*image_size*image_size-Net\n",
    "    '''\n",
    "    h, w = img.shape[-2], img.shape[-1]\n",
    "    max_ = max(h,w)\n",
    "    pad_t = pad_d = h_pad = (max_-h)/2\n",
    "    if h_pad % 1 > 0:\n",
    "        pad_t = int(h_pad - .5)\n",
    "        pad_d = int(h_pad + .5)\n",
    "    pad_l = pad_r = w_pad = (max_-w)/2\n",
    "    if w_pad % 1 > 0:\n",
    "        pad_l = int(w_pad - .5)\n",
    "        pad_r = int(w_pad + .5)\n",
    "    pad_list = [int(pad_l), int(pad_t), int(pad_r), int(pad_d)]\n",
    "    trans = v2.Compose([\n",
    "        v2.Pad(pad_list, 0, 'constant'),\n",
    "        v2.Resize((image_size,image_size),antialias=True)\n",
    "    ])\n",
    "    return trans(img) #unsqueeze for batch dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_square_pad(img, net_ge_img_mask):\n",
    "    '''\n",
    "    对图像进行Square Pad的逆操作，输入原始图像来判断各个方向需要减少多少行零填充，size为3*H*W\n",
    "    输入的为FAT-Net生成的图像掩码，size为1*1*224*224\n",
    "    返回图像size为1*3*224*224，用于输入FAT-Net\n",
    "    '''\n",
    "    h, w = img.shape[-2], img.shape[-1]\n",
    "    max_ = max(h,w)\n",
    "    h_pad = (max_-h)/2\n",
    "    if h_pad % 1 > 0:\n",
    "        pad_t = int(h_pad - .5)\n",
    "        pad_d = int(h_pad + .5)\n",
    "    else:\n",
    "        pad_t = int(h_pad)\n",
    "        pad_d = int(h_pad)\n",
    "    w_pad = (max_-w)/2\n",
    "    if w_pad % 1 > 0:\n",
    "        pad_l = int(w_pad - .5)\n",
    "        pad_r = int(w_pad + .5)\n",
    "    else:\n",
    "        pad_l = int(w_pad)\n",
    "        pad_r = int(w_pad)\n",
    "    trans = v2.Compose([\n",
    "        v2.Resize((max_,max_), antialias=True)\n",
    "    ])\n",
    "    return trans(net_ge_img_mask[0:])[..., pad_t:max_-pad_d, pad_l:max_-pad_r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_map(mask):\n",
    "    assert torch.all((mask == 0) | (mask == 1)) # 必须为0,1掩码\n",
    "\n",
    "    device = mask.device\n",
    "    conv_kernal = torch.ones((1,1,3,3), device=device)\n",
    "    conv_mask = torch.nn.functional.conv2d(mask, conv_kernal, padding=1) # pad=1防止图像大小改变\n",
    "    conv_mask = torch.where((conv_mask > 0) & (conv_mask < 9), torch.ones_like(conv_mask), torch.zeros_like(conv_mask)) # 落在0-9之间表明3*3的区域不全为0，且不全为1\n",
    "    edge = torch.mul(conv_mask, mask) # 只有mask上不为0，且附近3*3的区域不全为0，且不全为1，edge的位置才为1，否则为0\n",
    "    edge = edge.squeeze() # squeeze是因为之后叠加边缘图需要保证必须是二维张量\n",
    "\n",
    "    return edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# unet hyper parameterts\n",
    "model_channnels = 128\n",
    "in_channels = 4\n",
    "out_channels = 1\n",
    "num_res_blocks = 1\n",
    "attn_resolutions = [] # if use, default is [16]\n",
    "dropout = 0.0\n",
    "channel_mult = (1, 1, 2, 2, 4, 4) if image_size == 256 else None\n",
    "dims = 2\n",
    "num_classes = None\n",
    "num_heads = 4 # not used in model\n",
    "num_heads_upsample = -1 # not used in model\n",
    "use_checkpoint = False\n",
    "use_scale_shift_norm = False\n",
    "\n",
    "# diffusion hyper parameters\n",
    "steps = 1000\n",
    "learn_sigma = False\n",
    "predict_xstart = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_unet_root = \"./\"\n",
    "diff_unet_path = os.path.join(diff_unet_root, \"./final_result/diff_unet_v1_withgan_withss.pt\")\n",
    "HD95 = HausdorffDistanceMetric(include_background=True, percentile=95.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diff_UNet model load\n",
    "\n",
    "DIFF_UNET = UNetModel_WithSSF(model_channels=model_channnels, in_channels=in_channels, out_channels=out_channels, channel_mult=channel_mult, num_res_blocks=num_res_blocks, attention_resolutions=attn_resolutions, dropout = dropout, dims=dims, num_classes=num_classes, num_heads=num_heads, num_heads_upsample=num_heads_upsample, use_checkpoint=use_checkpoint, use_scale_shift_norm=use_scale_shift_norm);\n",
    "DIFF_UNET.load_resunet(if_pre=False, in_channels=3);\n",
    "state_dict = torch.load(diff_unet_path);\n",
    "DIFF_UNET.load_state_dict(state_dict=state_dict);\n",
    "DIFF_UNET.to(DEVICE)\n",
    "\n",
    "\n",
    "# diffusion = create_gaussian_diffusion(steps=steps, learn_sigma=learn_sigma, predict_xstart=predict_xstart)\n",
    "diffusion = create_gaussian_diffusion(steps=steps, timestep_respacing=\"10\", learn_sigma=learn_sigma, predict_xstart=predict_xstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import ISIC_ori_test_Dataset\n",
    "test_data_path = \"d:\\DATA\\ISIC2016\"\n",
    "image_size = 256\n",
    "testdata = ISIC_ori_test_Dataset(test_data_path)\n",
    "ori_test_loader = DataLoader(testdata, batch_size=1, shuffle=False)\n",
    "img_save_path = \"./final_result/images\"\n",
    "if not os.path.exists(img_save_path):\n",
    "    os.makedirs(img_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thres_bi(x):\n",
    "    x = torch.where(x > 0.5, 1., 0.)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对增强后数据集的测试集的每一张图进行测试，并保存（保存的是同一张图像，因此会覆盖）\n",
    "# 通过调试时，在断点暂停来查看最后的分割结果，大概查看模型的性能\n",
    "# 下面两个二选一\n",
    "\n",
    "SegNet = DIFF_UNET\n",
    "totaldice=0\n",
    "totalsens=0\n",
    "totalacc=0\n",
    "totalhd95=0\n",
    "totaliou=0\n",
    "stepValidcnt=0\n",
    "num_ensemble = 5\n",
    "\n",
    "with torch.no_grad():\n",
    "    SegNet.eval()\n",
    "    for (img,real_mask, id) in tqdm(ori_test_loader):\n",
    "        id = id[0]\n",
    "        (img,real_mask)=(img.to(DEVICE),real_mask.to(DEVICE))\n",
    "        img_pad = square_pad(img, image_size)\n",
    "        img_pad = img_pad.repeat(num_ensemble, 1, 1, 1)\n",
    "        mask_shape = (num_ensemble, 1, img_pad.shape[-2], img_pad.shape[-1])\n",
    "        fake_mask = diffusion.ddim_sample_loop(model=SegNet, shape =mask_shape, denoised_fn=thres_bi, clip_denoised=True, model_kwargs={'img': img_pad}, progress=False)\n",
    "        fake_mask = inv_square_pad(img, fake_mask)\n",
    "        fake_mask = torch.mean(fake_mask, 0, keepdim=True)\n",
    "\n",
    "        # resize mask to 256*256\n",
    "        scale = image_size / max(fake_mask.shape[-1], fake_mask.shape[-2])\n",
    "        fake_mask_256 = F.interpolate(fake_mask, scale_factor=scale, mode='bilinear')\n",
    "        real_mask_256 = F.interpolate(real_mask, scale_factor=scale, mode='nearest')\n",
    "        fake_mask_256 = torch.where(fake_mask_256 > 0.5, torch.ones_like(fake_mask_256), torch.zeros_like(fake_mask_256))\n",
    "        fake_mask = torch.where(fake_mask > 0.5, torch.ones_like(fake_mask), torch.zeros_like(fake_mask))\n",
    "\n",
    "        # metric\n",
    "        conf_mat=get_confusion_matrix(fake_mask,real_mask.int())\n",
    "        batch_dice=compute_confusion_matrix_metric('f1 score', conf_mat)\n",
    "        batch_sens=compute_confusion_matrix_metric('sensitivity', conf_mat)\n",
    "        batch_acc=compute_confusion_matrix_metric('accuracy', conf_mat)\n",
    "        batch_hd95=HD95(fake_mask_256, real_mask_256.int())\n",
    "        batch_iou=compute_iou(fake_mask, real_mask.int())\n",
    "\n",
    "        totaldice+=batch_dice.mean()\n",
    "        totalsens+=batch_sens.mean()\n",
    "        totalacc+=batch_acc.mean()\n",
    "        totalhd95+=batch_hd95.mean()\n",
    "        totaliou+=batch_iou.mean()\n",
    "\n",
    "        stepValidcnt+=1\n",
    "        img = torch.clip(img, 0., 1.) # 不加的话，img可能会有大于1的值\n",
    "        saved_img = torch.cat((img[0], real_mask.squeeze(0).repeat(3,1,1), fake_mask.squeeze(0).repeat(3,1,1)),dim=1).permute(1,2,0).cpu().numpy()\n",
    "        plt.imsave(\"test.png\", np.clip(saved_img,0.,1.))\n",
    "        # saved_img = fake_mask.squeeze(0).repeat(3,1,1).permute(1,2,0).cpu().numpy()\n",
    "        # plt.imsave(os.path.join(img_save_path, id+\"_gen.png\"), np.clip(saved_img,0.,1.))\n",
    "\n",
    "print(\"{} Model Average Dice is {}\".format(SegNet.type.__name__, totaldice / stepValidcnt))\n",
    "print(\"{} Model Average Sensitivity is {}\".format(SegNet.type.__name__, totalsens / stepValidcnt))\n",
    "print(\"{} Model Average Accuracy is {}\".format(SegNet.type.__name__, totalacc / stepValidcnt))\n",
    "print(\"{} Model Average HD95 is {}\".format(SegNet.type.__name__, totalhd95 / stepValidcnt))\n",
    "print(\"{} Model Average Iou is {}\".format(SegNet.type.__name__, totaliou / stepValidcnt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LDCT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
